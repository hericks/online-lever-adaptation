{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "import random\n",
    "from itertools import combinations\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from levers import IteratedLeverEnvironment\n",
    "from levers.learner import DRQNetwork, DRQNAgent\n",
    "from levers.helpers import generate_binary_patterns\n",
    "from levers.partners import FixedPatternPartner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_drqn_agent(train_partners):\n",
    "    # Environment settings\n",
    "    payoffs = [1., 1.]\n",
    "    truncated_length = 100\n",
    "\n",
    "    # Learner settings\n",
    "    hidden_size = 4\n",
    "    capacity = 8\n",
    "    batch_size = 4\n",
    "    lr = 0.01\n",
    "    gamma = 0.99\n",
    "    len_update_cycle = 4\n",
    "    tau = 5e-4\n",
    "\n",
    "    # Training settings\n",
    "    num_episodes = 1000\n",
    "    epsilon = 0.3\n",
    "\n",
    "    # Construct list of environments to train on\n",
    "    train_envs = [\n",
    "        IteratedLeverEnvironment(\n",
    "            payoffs, truncated_length+1, FixedPatternPartner(list(pattern)),\n",
    "            False, False)\n",
    "        for pattern in train_partners\n",
    "    ]\n",
    "\n",
    "    # Reset learner\n",
    "    learner = DRQNAgent(\n",
    "        DRQNetwork(\n",
    "            input_size=len(train_envs[0].dummy_obs()),\n",
    "            hidden_size=hidden_size,\n",
    "            n_actions=train_envs[0].n_actions()),\n",
    "        capacity, batch_size, lr, gamma, len_update_cycle, tau\n",
    "    )\n",
    "\n",
    "    # Train learner\n",
    "    for episode in range(num_episodes):\n",
    "        # Sample reset environment from training environments\n",
    "        env = random.sample(train_envs, 1)[0]\n",
    "        obs = env.reset()\n",
    "        learner.reset_trajectory_buffer(init_obs=obs)\n",
    "\n",
    "        # Step through environment\n",
    "        for step in range(truncated_length):\n",
    "            action = learner.act(obs, epsilon)\n",
    "            next_obs, reward, done = env.step(action)\n",
    "            learner.update_trajectory_buffer(action, reward, next_obs, done)\n",
    "            obs = next_obs \n",
    "\n",
    "        # Flush experience to replay memory and train learner\n",
    "        learner.flush_trajectory_buffer()\n",
    "        learner.train()\n",
    "\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_drqn_xplay(learner1, learner2):\n",
    "    # Environment parameters\n",
    "    payoffs = [1., 1.]\n",
    "    truncated_length = 100\n",
    "\n",
    "    # Initialize environment without lever game partner\n",
    "    env = IteratedLeverEnvironment(\n",
    "        payoffs,\n",
    "        truncated_length+1, \n",
    "        include_payoffs=False,\n",
    "        include_step=False\n",
    "    )\n",
    "\n",
    "    # Reset learners' hidden states\n",
    "    learner1.hidden = None\n",
    "    learner2.hidden = None\n",
    "\n",
    "    ret = 0\n",
    "    joint_obs = env.reset()\n",
    "    obs1 = joint_obs[0,]\n",
    "    obs2 = joint_obs[1,]\n",
    "\n",
    "    for _ in range(truncated_length):\n",
    "        action1 = learner1.act(obs1)\n",
    "        action2 = learner2.act(obs2)\n",
    "\n",
    "        joint_next_obs, reward, done = env.step([action1, action2])\n",
    "\n",
    "        obs1 = joint_next_obs[0,]\n",
    "        obs2 = joint_next_obs[1,]\n",
    "\n",
    "        ret += reward\n",
    "\n",
    "    return ret / truncated_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DRQN agent: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19.\n"
     ]
    }
   ],
   "source": [
    "# Number of agents for crossplay\n",
    "n_agents = 20\n",
    "\n",
    "# Train agents\n",
    "patterns = generate_binary_patterns(length=3)\n",
    "train_partners = random.sample(list(combinations(patterns, 4)), n_agents)\n",
    "agents = []\n",
    "print('Training DRQN agent: ', end='')\n",
    "for agent_id in range(n_agents):\n",
    "    end = '.\\n' if agent_id == n_agents - 1 else ' '\n",
    "    print(f'{agent_id}', end=end) \n",
    "    agents.append(train_drqn_agent(train_partners[agent_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/engs-oxfair3/orie4536/online-lever-adaptation/experiments/eval_drqn_xplay.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhtc-g040/data/engs-oxfair3/orie4536/online-lever-adaptation/experiments/eval_drqn_xplay.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m a1_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_agents):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhtc-g040/data/engs-oxfair3/orie4536/online-lever-adaptation/experiments/eval_drqn_xplay.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m a2_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_agents):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhtc-g040/data/engs-oxfair3/orie4536/online-lever-adaptation/experiments/eval_drqn_xplay.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         learner1 \u001b[39m=\u001b[39m deepcopy(agents[a1_idx])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhtc-g040/data/engs-oxfair3/orie4536/online-lever-adaptation/experiments/eval_drqn_xplay.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         learner2 \u001b[39m=\u001b[39m deepcopy(agents[a2_idx])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhtc-g040/data/engs-oxfair3/orie4536/online-lever-adaptation/experiments/eval_drqn_xplay.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         scores[a1_idx, a2_idx] \u001b[39m=\u001b[39m eval_drqn_xplay(learner1, learner2)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:210\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[39m=\u001b[39mdeepcopy):\n\u001b[0;32m--> 210\u001b[0m     y \u001b[39m=\u001b[39m [deepcopy(a, memo) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x]\n\u001b[1;32m    211\u001b[0m     \u001b[39m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:210\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[39m=\u001b[39mdeepcopy):\n\u001b[0;32m--> 210\u001b[0m     y \u001b[39m=\u001b[39m [deepcopy(a, memo) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x]\n\u001b[1;32m    211\u001b[0m     \u001b[39m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:89\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__deepcopy__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, memo)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_leaf:\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly Tensors created explicitly by the user \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m(graph leaves) support the deepcopy protocol at the moment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39min\u001b[39;00m memo:\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m memo[\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    }
   ],
   "source": [
    "# Evaluate agents in crossplay\n",
    "scores = torch.zeros((n_agents, n_agents))\n",
    "for a1_idx in range(n_agents):\n",
    "    for a2_idx in range(n_agents):\n",
    "        agents[a1_idx].hidden = None\n",
    "        agents[a2_idx].hidden = None\n",
    "        learner1 = deepcopy(agents[a1_idx])\n",
    "        learner2 = deepcopy(agents[a2_idx])\n",
    "        scores[a1_idx, a2_idx] = eval_drqn_xplay(learner1, learner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw crossplay matrix\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "cax = ax.matshow(scores.mean(dim=-1), vmin=0, vmax=1)\n",
    "fig.colorbar(cax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0da39f85071e8dc4a619b3f51e18c7a210d5ff72e9e22a4ce1dbec0af1e68dbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
