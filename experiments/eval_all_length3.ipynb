{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import deque\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from levers import IteratedLeverEnvironment\n",
    "from levers.partners import FixedPatternPartner\n",
    "from levers.learner import DQNAgent, DRQNetwork, DRQNAgent, Transition\n",
    "from levers.helpers import generate_binary_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fee0c80ad70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class with dot notation access similar to wandb.config\n",
    "class WandbDict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODQL_agent_from_config(\n",
    "    env: IteratedLeverEnvironment, config: WandbDict\n",
    "):\n",
    "    # Create base class\n",
    "    hist_rep = nn.LSTM(\n",
    "        input_size=len(env.dummy_obs()),\n",
    "        hidden_size=config.hist_rep_dim\n",
    "    )\n",
    "    learner = DQNAgent(\n",
    "        q_net=nn.Sequential(\n",
    "            nn.Linear(config.hist_rep_dim, config.dqn_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.dqn_hidden_dim, env.n_actions()),\n",
    "        ),\n",
    "        capacity=0,\n",
    "        batch_size=0,\n",
    "        lr=config.dqn_lr,\n",
    "        tau=config.dqn_tau,\n",
    "        len_update_cycle=config.dqn_len_update_cycle,\n",
    "        gamma=config.dqn_gamma,\n",
    "        use_running_memory=config.dqn_use_running_memory,\n",
    "    )\n",
    "\n",
    "    # Load parameters from disk\n",
    "    patterns = generate_binary_patterns(3)\n",
    "    train_configurations = list(combinations(patterns, 4))\n",
    "    train_patterns=train_configurations[config.exp_train_patterns_index]\n",
    "    train_seed=config.exp_train_seed\n",
    "\n",
    "    # Load history representation network's parameters\n",
    "    hist_rep_name = f\"odql_all_length3/models/hist-{train_patterns}-{train_seed}.pt\"\n",
    "    hist_rep.load_state_dict(torch.load(hist_rep_name))\n",
    "\n",
    "    # Load Q-network's parameters\n",
    "    q_net_name = f\"odql_all_length3/models/q-{train_patterns}-{train_seed}.pt\"\n",
    "    learner.q_net.load_state_dict(torch.load(q_net_name))\n",
    "\n",
    "    return hist_rep, learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRQN_agent_from_config(\n",
    "    env: IteratedLeverEnvironment, config: WandbDict\n",
    "):\n",
    "    # Load base class\n",
    "    learner = DRQNAgent(\n",
    "        q_net=DRQNetwork(\n",
    "            rnn=nn.LSTM(\n",
    "                input_size=len(env.dummy_obs()),\n",
    "                hidden_size=config.drqn_rnn_hidden_dim,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            fnn=nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    in_features=config.drqn_rnn_hidden_dim,\n",
    "                    out_features=config.drqn_fnn_hidden_dim,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(\n",
    "                    in_features=config.drqn_fnn_hidden_dim,\n",
    "                    out_features=env.n_actions(),\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        capacity=config.drqn_capacity,\n",
    "        batch_size=config.drqn_batch_size,\n",
    "        lr=config.drqn_lr,\n",
    "        tau=config.drqn_tau,\n",
    "        gamma=config.drqn_gamma,\n",
    "        len_update_cycle=config.drqn_len_update_cycle,\n",
    "    )\n",
    "\n",
    "    # Load parameters from disk\n",
    "    patterns = generate_binary_patterns(3)\n",
    "    train_configurations = list(combinations(patterns, 4))\n",
    "    train_patterns=train_configurations[config.exp_train_patterns_index]\n",
    "    train_seed=config.exp_train_seed\n",
    "\n",
    "    # Load Q-network's parameters\n",
    "    drqn_name = f\"drqn_all_length3/models/q-{train_patterns}-{train_seed}.pt\"\n",
    "    learner.q_net.load_state_dict(torch.load(drqn_name))\n",
    "\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ODQL_learner(config, env, eps_start, eps_n_decay_steps):\n",
    "    hist_rep, learner = ODQL_agent_from_config(env, config)\n",
    "\n",
    "    # Prepare stats\n",
    "    epi_return, epi_greedy_return, epi_n_greedy_steps = 0, 0, 0\n",
    "    last_actions = deque(maxlen=4)\n",
    "\n",
    "    # Reset environment and learner\n",
    "    learner.reset()\n",
    "    obs = env.reset()\n",
    "    obs_rep, hidden = hist_rep(obs.unsqueeze(0))\n",
    "    for step in range(env.episode_length - 1):\n",
    "        eps = eps_start * max(1 - step / eps_n_decay_steps, 0)\n",
    "        action, greedy = learner.act(obs_rep.squeeze(0), eps)\n",
    "        next_obs, reward, done = env.step(action)\n",
    "        next_obs_rep, next_hidden = hist_rep(next_obs.unsqueeze(0), hidden)\n",
    "        learner.update_memory(\n",
    "            Transition(\n",
    "                obs_rep.squeeze(0).detach(),\n",
    "                action,\n",
    "                next_obs_rep.squeeze(0).detach(),\n",
    "                reward,\n",
    "                done,\n",
    "            )\n",
    "        )\n",
    "        learner.train()\n",
    "        epi_return += reward\n",
    "        epi_greedy_return += reward if greedy else 0\n",
    "        epi_n_greedy_steps += 1 if greedy else 0\n",
    "        last_actions.append(action if greedy else -1)\n",
    "        obs_rep = next_obs_rep\n",
    "        hidden = next_hidden\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'return': epi_return,\n",
    "        'normalized_greedy_return': epi_greedy_return / epi_n_greedy_steps * 100,\n",
    "        'greedy_return': epi_greedy_return,\n",
    "        'n_greedy_steps': epi_n_greedy_steps,\n",
    "        'last_actions': last_actions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_DRQN_learner(config, env):\n",
    "    learner = DRQN_agent_from_config(env, config)\n",
    "\n",
    "    # Prepare stats\n",
    "    epi_return = 0\n",
    "    last_actions = deque(maxlen=4)\n",
    "\n",
    "    # Reset environment and learner\n",
    "    obs = env.reset()\n",
    "    learner.reset_new_episode(init_obs=obs)\n",
    "    for _ in range(env.episode_length - 1):\n",
    "        action = learner.act(obs)\n",
    "        last_actions.append(action)\n",
    "        next_obs, reward, done = env.step(action)\n",
    "        obs = next_obs\n",
    "        epi_return += reward\n",
    "\n",
    "    return {\n",
    "        'return': epi_return,\n",
    "        'last_actions': last_actions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ODQL_crossplay(config1, config2, eps_start, eps_n_decay_steps):\n",
    "    env = IteratedLeverEnvironment(\n",
    "        payoffs=[1., 1.0],\n",
    "        n_iterations=100+1,\n",
    "        include_step=False,\n",
    "        include_payoffs=False,\n",
    "    )\n",
    "\n",
    "    hist_rep1, agent1 = ODQL_agent_from_config(env, config1)\n",
    "    hist_rep2, agent2 = ODQL_agent_from_config(env, config2)\n",
    "\n",
    "    # Prepare stats\n",
    "    epi_return, epi_greedy_return, epi_n_greedy_steps = 0, 0, 0\n",
    "    last_actions = deque(maxlen=4)\n",
    "\n",
    "    joint_obs = env.reset()\n",
    "\n",
    "    agent1.reset()\n",
    "    agent2.reset()\n",
    "\n",
    "    obs_rep1, hidden1 = hist_rep1(joint_obs[0].unsqueeze(0))\n",
    "    obs_rep2, hidden2 = hist_rep2(joint_obs[1].unsqueeze(0))\n",
    "\n",
    "    for step in range(env.episode_length - 1):\n",
    "        # Get agents' actions\n",
    "        eps = eps_start * max(1 - step / eps_n_decay_steps, 0)\n",
    "        action1, greedy1 = agent1.act(obs_rep1.squeeze(0), eps)\n",
    "        action2, greedy2 = agent2.act(obs_rep2.squeeze(0), eps)\n",
    "\n",
    "        next_joint_obs, reward, done = env.step([action1, action2])\n",
    "\n",
    "        next_obs_rep1, hidden1 = hist_rep1(next_joint_obs[0].unsqueeze(0), hidden1)\n",
    "        next_obs_rep2, hidden2 = hist_rep2(next_joint_obs[1].unsqueeze(0), hidden2)\n",
    "\n",
    "        # Train agent 1\n",
    "        agent1.update_memory(\n",
    "            Transition(\n",
    "                obs_rep1.squeeze(0).detach(),\n",
    "                action1,\n",
    "                next_obs_rep1.squeeze(0).detach(),\n",
    "                reward,\n",
    "                done,\n",
    "            )\n",
    "        )\n",
    "        agent1.train()\n",
    "\n",
    "        # Train agent 2\n",
    "        agent2.update_memory(\n",
    "            Transition(\n",
    "                obs_rep2.squeeze(0).detach(),\n",
    "                action2,\n",
    "                next_obs_rep2.squeeze(0).detach(),\n",
    "                reward,\n",
    "                done,\n",
    "            )\n",
    "        )\n",
    "        agent2.train()\n",
    "\n",
    "        # Update stats\n",
    "        epi_return += reward\n",
    "        epi_greedy_return += reward if greedy1 and greedy2 else 0\n",
    "        epi_n_greedy_steps += 1 if greedy1 and greedy2 else 0\n",
    "\n",
    "        # Prepare next step\n",
    "        obs_rep1 = next_obs_rep1\n",
    "        obs_rep2 = next_obs_rep2\n",
    "\n",
    "    return {\n",
    "        'return': epi_return,\n",
    "        'normalized_greedy_return': epi_greedy_return / epi_n_greedy_steps * 100,\n",
    "        'greedy_return': epi_greedy_return,\n",
    "        'n_greedy_steps': epi_n_greedy_steps,\n",
    "        'last_actions': last_actions\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_DRQN_crossplay(config1, config2):\n",
    "    env = IteratedLeverEnvironment(\n",
    "        payoffs=[1., 1.],\n",
    "        n_iterations=100+1,\n",
    "        include_step=False,\n",
    "        include_payoffs=False,\n",
    "    )\n",
    "\n",
    "    agent1 = DRQN_agent_from_config(env, config1)\n",
    "    agent2 = DRQN_agent_from_config(env, config2)\n",
    "\n",
    "    joint_obs = env.reset()\n",
    "    agent1.reset()\n",
    "    agent2.reset()\n",
    "\n",
    "    epi_return = 0\n",
    "    for step in range(env.episode_length - 1):\n",
    "        action1 = agent1.act(joint_obs[0])\n",
    "        action2 = agent2.act(joint_obs[1])\n",
    "        next_joint_obs, reward, _ = env.step([action1, action2])\n",
    "        epi_return += reward\n",
    "        joint_obs = next_joint_obs\n",
    "\n",
    "    return {\n",
    "        'return': epi_return\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = generate_binary_patterns(3)\n",
    "train_configurations = list(combinations(patterns, 4))\n",
    "\n",
    "envs = [\n",
    "    IteratedLeverEnvironment(\n",
    "        payoffs=[1., 1.],\n",
    "        n_iterations=100 + 1,\n",
    "        partner=FixedPatternPartner(pattern),\n",
    "        include_step=False,\n",
    "        include_payoffs=False,\n",
    "    )\n",
    "    for pattern in patterns\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODQL Agent Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ODQL agents were trained for 15 different seeds each.\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api(timeout=60)\n",
    "\n",
    "# Obtain runs from ODQL parameter sweep\n",
    "runs = api.runs(\"hericks/odql-all-length3\")\n",
    "\n",
    "# Obtain parameter configs for each run\n",
    "configs = []\n",
    "for run in runs: \n",
    "    config = {k:v for k,v in run.config.items() if not k.startswith('_')}\n",
    "    configs.append(WandbDict(config))\n",
    "\n",
    "# Obtain number of training seeds per configuration\n",
    "n_train_seeds = max([config.exp_train_seed for config in configs]) + 1\n",
    "print(f\"The ODQL agents were trained for {n_train_seeds} different seeds each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for config_index, config in enumerate(configs):\n",
    "    if (config_index + 1) % 200 == 0:\n",
    "        print(config_index + 1)\n",
    "    for eval_index, eval_pattern in enumerate(patterns):\n",
    "        results = eval_ODQL_learner(\n",
    "            config=config,\n",
    "            env=envs[eval_index],\n",
    "            eps_start=1.0,\n",
    "            eps_n_decay_steps=33,\n",
    "        )\n",
    "        results.update({\n",
    "            'method': 'ODQL',\n",
    "            'train_patterns': train_configurations[config.exp_train_patterns_index],\n",
    "            'train_seed': config.exp_train_seed,\n",
    "            'eval_pattern': eval_pattern,\n",
    "            'seen_at_train_time': eval_pattern in train_configurations[config.exp_train_patterns_index],\n",
    "        })\n",
    "        results_list.append(results)\n",
    "\n",
    "odql_results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train_patterns</th>\n",
       "      <th>train_seed</th>\n",
       "      <th>eval_pattern</th>\n",
       "      <th>seen_at_train_time</th>\n",
       "      <th>return</th>\n",
       "      <th>normalized_greedy_return</th>\n",
       "      <th>greedy_return</th>\n",
       "      <th>n_greedy_steps</th>\n",
       "      <th>last_actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.853659</td>\n",
       "      <td>54.0</td>\n",
       "      <td>82</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.073171</td>\n",
       "      <td>55.0</td>\n",
       "      <td>82</td>\n",
       "      <td>[1, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.823529</td>\n",
       "      <td>84.0</td>\n",
       "      <td>85</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.962963</td>\n",
       "      <td>51.0</td>\n",
       "      <td>81</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>89.0</td>\n",
       "      <td>98.795181</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83</td>\n",
       "      <td>[1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>57.0</td>\n",
       "      <td>65.853659</td>\n",
       "      <td>54.0</td>\n",
       "      <td>82</td>\n",
       "      <td>[1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 1, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82</td>\n",
       "      <td>[1, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>ODQL</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     method                                train_patterns  train_seed  \\\n",
       "0      ODQL  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "1      ODQL  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "2      ODQL  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "3      ODQL  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "4      ODQL  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "...     ...                                           ...         ...   \n",
       "8395   ODQL  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8396   ODQL  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8397   ODQL  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8398   ODQL  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8399   ODQL  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "\n",
       "     eval_pattern  seen_at_train_time  return  normalized_greedy_return  \\\n",
       "0       (0, 0, 0)               False    89.0                 95.348837   \n",
       "1       (0, 0, 1)               False    65.0                 65.853659   \n",
       "2       (0, 1, 0)               False    65.0                 67.073171   \n",
       "3       (0, 1, 1)               False    90.0                 98.823529   \n",
       "4       (1, 0, 0)                True    62.0                 62.962963   \n",
       "...           ...                 ...     ...                       ...   \n",
       "8395    (0, 1, 1)                True    93.0                100.000000   \n",
       "8396    (1, 0, 0)               False    89.0                 98.795181   \n",
       "8397    (1, 0, 1)               False    57.0                 65.853659   \n",
       "8398    (1, 1, 0)               False    93.0                100.000000   \n",
       "8399    (1, 1, 1)               False    91.0                100.000000   \n",
       "\n",
       "      greedy_return  n_greedy_steps  last_actions  \n",
       "0              82.0              86  [0, 0, 0, 0]  \n",
       "1              54.0              82  [0, 1, 1, 0]  \n",
       "2              55.0              82  [1, 1, 0, 1]  \n",
       "3              84.0              85  [0, 1, 1, 0]  \n",
       "4              51.0              81  [0, 0, 0, 0]  \n",
       "...             ...             ...           ...  \n",
       "8395           87.0              87  [0, 1, 1, 0]  \n",
       "8396           82.0              83  [1, 0, 0, 1]  \n",
       "8397           54.0              82  [1, 0, 0, 1]  \n",
       "8398           82.0              82  [1, 1, 0, 1]  \n",
       "8399           84.0              84  [1, 1, 1, 1]  \n",
       "\n",
       "[8400 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odql_results_df = odql_results_df[['method', 'train_patterns', 'train_seed', 'eval_pattern', 'seen_at_train_time', 'return', 'normalized_greedy_return', 'greedy_return', 'n_greedy_steps', 'last_actions']]\n",
    "odql_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 88.18 | 95.99\n",
      "Train: 90.03 | 98.22\n",
      "Test: 86.33 | 93.76\n"
     ]
    }
   ],
   "source": [
    "train = odql_results_df['seen_at_train_time']\n",
    "print(f\"Overall: {odql_results_df['return'].mean():.2f} | {odql_results_df['normalized_greedy_return'].mean():.2f}\")\n",
    "print(f\"Train: {odql_results_df[train]['return'].mean():.2f} | {odql_results_df[train]['normalized_greedy_return'].mean():.2f}\")\n",
    "print(f\"Test: {odql_results_df[~train]['return'].mean():.2f} | {odql_results_df[~train]['normalized_greedy_return'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DRQN Agent Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DRQN agents were trained for 15 different seeds each.\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api(timeout=60)\n",
    "\n",
    "# Obtain runs from ODQL parameter sweep\n",
    "runs = api.runs(\"hericks/drqn-all-length3\")\n",
    "\n",
    "# Obtain parameter configs for each run\n",
    "configs = []\n",
    "for run in runs: \n",
    "    config = {k:v for k,v in run.config.items() if not k.startswith('_')}\n",
    "    configs.append(WandbDict(config))\n",
    "\n",
    "# Obtain number of training seeds per configuration\n",
    "n_train_seeds = max([config.exp_train_seed for config in configs]) + 1\n",
    "print(f\"The DRQN agents were trained for {n_train_seeds} different seeds each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for config_index, config in enumerate(configs):\n",
    "    if (config_index + 1) % 200 == 0:\n",
    "        print(config_index + 1)\n",
    "    for eval_index, eval_pattern in enumerate(patterns):\n",
    "        try:\n",
    "            results = eval_DRQN_learner(\n",
    "                config=config,\n",
    "                env=envs[eval_index],\n",
    "            )\n",
    "            results.update({\n",
    "                'method': 'DRQN',\n",
    "                'train_patterns': train_configurations[config.exp_train_patterns_index],\n",
    "                'train_seed': config.exp_train_seed,\n",
    "                'eval_pattern': eval_pattern,\n",
    "                'seen_at_train_time': eval_pattern in train_configurations[config.exp_train_patterns_index],\n",
    "            })\n",
    "            results_list.append(results)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "drqn_results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train_patterns</th>\n",
       "      <th>train_seed</th>\n",
       "      <th>eval_pattern</th>\n",
       "      <th>seen_at_train_time</th>\n",
       "      <th>return</th>\n",
       "      <th>last_actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>99.0</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 1, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>DRQN</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     method                                train_patterns  train_seed  \\\n",
       "0      DRQN  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "1      DRQN  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "2      DRQN  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "3      DRQN  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "4      DRQN  ((1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))          14   \n",
       "...     ...                                           ...         ...   \n",
       "8395   DRQN  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8396   DRQN  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8397   DRQN  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8398   DRQN  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "8399   DRQN  ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1))           0   \n",
       "\n",
       "     eval_pattern  seen_at_train_time  return  last_actions  \n",
       "0       (0, 0, 0)               False     0.0  [1, 1, 1, 1]  \n",
       "1       (0, 0, 1)               False    98.0  [0, 0, 1, 0]  \n",
       "2       (0, 1, 0)               False    98.0  [0, 1, 0, 0]  \n",
       "3       (0, 1, 1)               False    99.0  [0, 1, 1, 0]  \n",
       "4       (1, 0, 0)                True   100.0  [1, 0, 0, 1]  \n",
       "...           ...                 ...     ...           ...  \n",
       "8395    (0, 1, 1)                True    34.0  [0, 0, 0, 0]  \n",
       "8396    (1, 0, 0)               False    66.0  [0, 0, 0, 0]  \n",
       "8397    (1, 0, 1)               False    33.0  [0, 0, 0, 0]  \n",
       "8398    (1, 1, 0)               False    33.0  [0, 0, 0, 0]  \n",
       "8399    (1, 1, 1)               False     0.0  [0, 0, 0, 0]  \n",
       "\n",
       "[8400 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drqn_results_df = drqn_results_df[['method', 'train_patterns', 'train_seed', 'eval_pattern', 'seen_at_train_time', 'return', 'last_actions']]\n",
    "drqn_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 85.65\n",
      "Train: 97.31\n",
      "Test: 74.00\n"
     ]
    }
   ],
   "source": [
    "train = drqn_results_df['seen_at_train_time']\n",
    "print(f\"Overall: {drqn_results_df['return'].mean():.2f}\")\n",
    "print(f\"Train: {drqn_results_df[train]['return'].mean():.2f}\")\n",
    "print(f\"Test: {drqn_results_df[~train]['return'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Crossplay Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = generate_binary_patterns(3)\n",
    "all_train_configurations = list(combinations(patterns, 4))\n",
    "n_train_configurations = len(all_train_configurations)\n",
    "\n",
    "n_xplay = 15\n",
    "xplay_train_configurations_indices = random.sample(range(n_train_configurations), n_xplay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODQL Crossplay Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api(timeout=60)\n",
    "\n",
    "needed_dict = {\n",
    "    i: False if i not in xplay_train_configurations_indices else True\n",
    "    for i in range(n_train_configurations)\n",
    "}\n",
    "\n",
    "# Obtain runs from ODQL parameter sweep\n",
    "runs = api.runs(\"hericks/odql-all-length3\")\n",
    "\n",
    "# Obtain parameter configs for each run\n",
    "crossplay_configs = []\n",
    "for run in runs: \n",
    "    config = WandbDict({k:v for k,v in run.config.items() if not k.startswith('_')})\n",
    "    if needed_dict[config.exp_train_patterns_index]:\n",
    "        crossplay_configs.append(WandbDict(config))\n",
    "        needed_dict[config.exp_train_patterns_index] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "rows_list = []\n",
    "for i in range(n_xplay):\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(i + 1)\n",
    "    for j in range(n_xplay):\n",
    "        res = eval_ODQL_crossplay(crossplay_configs[i], crossplay_configs[j], 0.5, 30)\n",
    "        res.update({\n",
    "            \"i1\": i,\n",
    "            \"i2\": j,\n",
    "            \"i1_train_patterns\": all_train_configurations[crossplay_configs[i].exp_train_patterns_index],\n",
    "            \"i2_train_patterns\": all_train_configurations[crossplay_configs[j].exp_train_patterns_index],\n",
    "        })\n",
    "        rows_list.append(res)\n",
    "\n",
    "odql_xplay_df = pd.DataFrame(rows_list)\n",
    "odql_xplay_df = odql_xplay_df[['i1', 'i2', 'i1_train_patterns', 'i2_train_patterns', 'return', 'normalized_greedy_return', 'greedy_return', 'n_greedy_steps', 'last_actions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i1</th>\n",
       "      <th>i2</th>\n",
       "      <th>i1_train_patterns</th>\n",
       "      <th>i2_train_patterns</th>\n",
       "      <th>return</th>\n",
       "      <th>normalized_greedy_return</th>\n",
       "      <th>greedy_return</th>\n",
       "      <th>n_greedy_steps</th>\n",
       "      <th>last_actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.057471</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>((0, 1, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>92.0</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>84.0</td>\n",
       "      <td>90</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>((0, 1, 0), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>93.0</td>\n",
       "      <td>97.802198</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>((0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>92.0</td>\n",
       "      <td>96.511628</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>((0, 1, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0))</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.181818</td>\n",
       "      <td>82.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))</td>\n",
       "      <td>((0, 0, 0), (0, 1, 1), (1, 0, 0), (1, 1, 0))</td>\n",
       "      <td>78.0</td>\n",
       "      <td>81.927711</td>\n",
       "      <td>68.0</td>\n",
       "      <td>83</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))</td>\n",
       "      <td>((0, 0, 0), (0, 1, 0), (1, 0, 0), (1, 1, 1))</td>\n",
       "      <td>90.0</td>\n",
       "      <td>96.511628</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))</td>\n",
       "      <td>((0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 0, 1))</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.863636</td>\n",
       "      <td>43.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (1, 1, 0), (1, 1, 1))</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))</td>\n",
       "      <td>((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))</td>\n",
       "      <td>91.0</td>\n",
       "      <td>97.701149</td>\n",
       "      <td>85.0</td>\n",
       "      <td>87</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     i1  i2                             i1_train_patterns  \\\n",
       "0     0   0  ((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))   \n",
       "1     0   1  ((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))   \n",
       "2     0   2  ((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))   \n",
       "3     0   3  ((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))   \n",
       "4     0   4  ((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))   \n",
       "..   ..  ..                                           ...   \n",
       "220  14  10  ((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))   \n",
       "221  14  11  ((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))   \n",
       "222  14  12  ((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))   \n",
       "223  14  13  ((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))   \n",
       "224  14  14  ((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))   \n",
       "\n",
       "                                i2_train_patterns  return  \\\n",
       "0    ((0, 1, 1), (1, 0, 0), (1, 1, 0), (1, 1, 1))    80.0   \n",
       "1    ((0, 1, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))    92.0   \n",
       "2    ((0, 1, 0), (1, 0, 0), (1, 1, 0), (1, 1, 1))    93.0   \n",
       "3    ((0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1))    92.0   \n",
       "4    ((0, 1, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0))    87.0   \n",
       "..                                            ...     ...   \n",
       "220  ((0, 0, 0), (0, 1, 1), (1, 0, 0), (1, 1, 0))    78.0   \n",
       "221  ((0, 0, 0), (0, 1, 0), (1, 0, 0), (1, 1, 1))    90.0   \n",
       "222  ((0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 0, 1))    49.0   \n",
       "223  ((0, 0, 0), (0, 0, 1), (1, 1, 0), (1, 1, 1))    95.0   \n",
       "224  ((0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1))    91.0   \n",
       "\n",
       "     normalized_greedy_return  greedy_return  n_greedy_steps last_actions  \n",
       "0                   85.057471           74.0              87           []  \n",
       "1                   93.333333           84.0              90           []  \n",
       "2                   97.802198           89.0              91           []  \n",
       "3                   96.511628           83.0              86           []  \n",
       "4                   93.181818           82.0              88           []  \n",
       "..                        ...            ...             ...          ...  \n",
       "220                 81.927711           68.0              83           []  \n",
       "221                 96.511628           83.0              86           []  \n",
       "222                 48.863636           43.0              88           []  \n",
       "223                100.000000           89.0              89           []  \n",
       "224                 97.701149           85.0              87           []  \n",
       "\n",
       "[225 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odql_xplay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODQL Crossplay: 71.84 | 74.70 (greedy)\n"
     ]
    }
   ],
   "source": [
    "print(f\"ODQL Crossplay: {odql_xplay_df['return'].mean():.2f} | {odql_xplay_df['normalized_greedy_return'].mean():.2f} (greedy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "odql_xplay_returns = np.zeros((n_xplay, n_xplay))\n",
    "odql_xplay_normalized_greedy_returns = np.zeros((n_xplay, n_xplay))\n",
    "for i in range(n_xplay):\n",
    "    for j in range(n_xplay):\n",
    "        row_mask = (odql_xplay_df['i1'] == i) & (odql_xplay_df['i2'] == j)\n",
    "        odql_xplay_returns[i, j] = odql_xplay_df[row_mask]['return'].item()\n",
    "        odql_xplay_normalized_greedy_returns[i, j] = odql_xplay_df[row_mask]['normalized_greedy_return'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee06cb2400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x1280 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(8, 16), dpi=80)\n",
    "ax1.matshow(odql_xplay_returns)\n",
    "ax2.matshow(odql_xplay_normalized_greedy_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRQN Crossplay Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api(timeout=60)\n",
    "\n",
    "needed_dict = {\n",
    "    i: False if i not in xplay_train_configurations_indices else True\n",
    "    for i in range(n_train_configurations)\n",
    "}\n",
    "\n",
    "# Obtain runs from DRQN parameter sweep\n",
    "runs = api.runs(\"hericks/drqn-all-length3\")\n",
    "\n",
    "# Obtain parameter configs for each run\n",
    "crossplay_configs = []\n",
    "for run in runs: \n",
    "    config = WandbDict({k:v for k,v in run.config.items() if not k.startswith('_')})\n",
    "    if needed_dict[config.exp_train_patterns_index]:\n",
    "        crossplay_configs.append(WandbDict(config))\n",
    "        needed_dict[config.exp_train_patterns_index] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "rows_list = []\n",
    "for i in range(n_xplay):\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(i + 1)\n",
    "    for j in range(n_xplay):\n",
    "        res = eval_DRQN_crossplay(crossplay_configs[i], crossplay_configs[j])\n",
    "        res.update({\n",
    "            \"i1\": i,\n",
    "            \"i2\": j,\n",
    "            \"i1_train_patterns\": all_train_configurations[crossplay_configs[i].exp_train_patterns_index],\n",
    "            \"i2_train_patterns\": all_train_configurations[crossplay_configs[j].exp_train_patterns_index],\n",
    "        })\n",
    "        rows_list.append(res)\n",
    "\n",
    "drqn_xplay_df = pd.DataFrame(rows_list)\n",
    "drqn_xplay_df = drqn_xplay_df[['i1', 'i2', 'i1_train_patterns', 'i2_train_patterns', 'return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      100.0\n",
       "1       67.0\n",
       "2      100.0\n",
       "3       67.0\n",
       "4       67.0\n",
       "       ...  \n",
       "220    100.0\n",
       "221     35.0\n",
       "222      2.0\n",
       "223    100.0\n",
       "224    100.0\n",
       "Name: return, Length: 225, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drqn_xplay_df['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossplay: 50.23\n"
     ]
    }
   ],
   "source": [
    "print(f\"Crossplay: {drqn_xplay_df['return'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "drqn_xplay_returns = np.zeros((n_xplay, n_xplay))\n",
    "for i in range(n_xplay):\n",
    "    for j in range(n_xplay):\n",
    "        row_mask = (drqn_xplay_df['i1'] == i) & (drqn_xplay_df['i2'] == j)\n",
    "        drqn_xplay_returns[i, j] = drqn_xplay_df[row_mask]['return'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee0834b0a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(drqn_xplay_returns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('evotorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93fe7ab9e9c894208fb85df19994ba2ccb8ea74b824756365ece5b2ab999c742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
